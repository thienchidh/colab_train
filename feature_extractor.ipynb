{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# See https://keras.io/api/applications/ for details\n",
    "\n",
    "class FeatureExtractorVGG16:\n",
    "    def __init__(self):\n",
    "        # base_model = VGG16(weights='imagenet')\n",
    "        # self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "        self.model = VGG16(weights='imagenet')\n",
    "\n",
    "    def extract(self, img):\n",
    "        \"\"\"\n",
    "        Extract a deep feature from an input image\n",
    "        Args:\n",
    "            img: from PIL.Image.open(path) or tensorflow.keras.preprocessing.image.load_img(path)\n",
    "\n",
    "        Returns:\n",
    "            feature (np.ndarray): deep feature with the shape=(4096, )\n",
    "        \"\"\"\n",
    "        img = img.resize((224, 224))  # VGG must take a 224x224 img as an input\n",
    "        img = img.convert('RGB')  # Make sure img is color\n",
    "        x = image.img_to_array(img)  # To np.array. Height x Width x Channel. dtype=float32\n",
    "        x = np.expand_dims(x, axis=0)  # (H, W, C)->(1, H, W, C), where the first elem is the number of img\n",
    "        x = preprocess_input(x)  # Subtracting avg values for each pixel\n",
    "        feature = self.model.predict(x)[0]  # (1, 4096) -> (4096, )\n",
    "        return feature / np.linalg.norm(feature)  # Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# See https://keras.io/api/applications/ for details\n",
    "\n",
    "class FeatureExtractorVGG19:\n",
    "    def __init__(self):\n",
    "        base_model = VGG19(weights='imagenet')\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "    def extract(self, img):\n",
    "        \"\"\"\n",
    "        Extract a deep feature from an input image\n",
    "        Args:\n",
    "            img: from PIL.Image.open(path) or tensorflow.keras.preprocessing.image.load_img(path)\n",
    "\n",
    "        Returns:\n",
    "            feature (np.ndarray): deep feature with the shape=(4096, )\n",
    "        \"\"\"\n",
    "        img = img.resize((224, 224))  # VGG must take a 224x224 img as an input\n",
    "        img = img.convert('RGB')  # Make sure img is color\n",
    "        x = image.img_to_array(img)  # To np.array. Height x Width x Channel. dtype=float32\n",
    "        x = np.expand_dims(x, axis=0)  # (H, W, C)->(1, H, W, C), where the first elem is the number of img\n",
    "        x = preprocess_input(x)  # Subtracting avg values for each pixel\n",
    "        feature = self.model.predict(x)[0]  # (1, 4096) -> (4096, )\n",
    "        return feature / np.linalg.norm(feature)  # Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# See https://keras.io/api/applications/ for details\n",
    "\n",
    "class FeatureExtractorResNet50:\n",
    "    def __init__(self):\n",
    "        self.model = ResNet50(weights='imagenet')\n",
    "\n",
    "    def extract(self, img):\n",
    "        \"\"\"\n",
    "        Extract a deep feature from an input image\n",
    "        Args:\n",
    "            img: from PIL.Image.open(path) or tensorflow.keras.preprocessing.image.load_img(path)\n",
    "\n",
    "        Returns:\n",
    "            feature (np.ndarray): deep feature with the shape=(4096, )\n",
    "        \"\"\"\n",
    "        img = img.resize((224, 224))  # VGG must take a 224x224 img as an input\n",
    "        img = img.convert('RGB')  # Make sure img is color\n",
    "        x = image.img_to_array(img)  # To np.array. Height x Width x Channel. dtype=float32\n",
    "        x = np.expand_dims(x, axis=0)  # (H, W, C)->(1, H, W, C), where the first elem is the number of img\n",
    "        x = preprocess_input(x)  # Subtracting avg values for each pixel\n",
    "        feature = self.model.predict(x)[0]  # (1, 4096) -> (4096, )\n",
    "        return feature / np.linalg.norm(feature)  # Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\18c29626-95ce-41f0-9082-597ea2363c3b.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\31fd2f8b-620c-405d-b9f9-5e676dbace96.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\40cdc4d8-61b5-4b1b-bfca-4a34541abddb.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\411a2823-10f9-47d8-bed1-7c3f715b5de4.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\5a9003f8-54ff-4b52-80c0-17654da7f333.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\5e1c4241-34f9-42b5-8112-e5fcb4484a02.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\690ad73d-fe25-48a7-94e5-ab1c4f1e03e3.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\6f904ea3-9899-46c3-a561-faec0bda7e86.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\7253c29e-932d-4669-b834-e3070730f788.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fe = FeatureExtractorVGG16()\n",
    "\n",
    "    for img_path in sorted(Path(\"./drive/MyDrive/data_clothes/images_original\").glob(\"*.jpg\")):\n",
    "        print(img_path)  # e.g., ./static/img/xxx.jpg\n",
    "        feature = fe.extract(img=Image.open(img_path))\n",
    "        feature_path = Path(\"./drive/MyDrive/data_clothes/static/feature/VGG16\") / (img_path.stem + \".npy\")  # e.g., ./static/feature/xxx.npy\n",
    "        np.save(feature_path, feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\18c29626-95ce-41f0-9082-597ea2363c3b.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\31fd2f8b-620c-405d-b9f9-5e676dbace96.jpg\ndrive\\MyDrive\\data_clothes\\static\\img\\40cdc4d8-61b5-4b1b-bfca-4a34541abddb.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\411a2823-10f9-47d8-bed1-7c3f715b5de4.jpg\ndrive\\MyDrive\\data_clothes\\static\\img\\5a9003f8-54ff-4b52-80c0-17654da7f333.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\5e1c4241-34f9-42b5-8112-e5fcb4484a02.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\690ad73d-fe25-48a7-94e5-ab1c4f1e03e3.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\6f904ea3-9899-46c3-a561-faec0bda7e86.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\\MyDrive\\data_clothes\\static\\img\\7253c29e-932d-4669-b834-e3070730f788.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fe = FeatureExtractorResNet50()\n",
    "\n",
    "    for img_path in sorted(Path(\"./drive/MyDrive/data_clothes/images_original\").glob(\"*.jpg\")):\n",
    "        print(img_path)  # e.g., ./static/img/xxx.jpg\n",
    "        feature = fe.extract(img=Image.open(img_path))\n",
    "        feature_path = Path(\"./drive/MyDrive/data_clothes/static/feature/ResNet50\") / (img_path.stem + \".npy\")  # e.g., ./static/feature/xxx.npy\n",
    "        np.save(feature_path, feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fe = FeatureExtractorVGG19()\n",
    "\n",
    "    for img_path in sorted(Path(\"./drive/MyDrive/data_clothes/images_original\").glob(\"*.jpg\")):\n",
    "        print(img_path)  # e.g., ./static/img/xxx.jpg\n",
    "        feature = fe.extract(img=Image.open(img_path))\n",
    "        feature_path = Path(\"./drive/MyDrive/data_clothes/static/feature/VGG19\") / (img_path.stem + \".npy\")  # e.g., ./static/feature/xxx.npy\n",
    "        np.save(feature_path, feature)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
